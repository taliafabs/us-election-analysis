---
title: "Forecasting the 2024 U.S. Presidential Election"
subtitle: "My subtitle if needed"
author: 
  - Talia Fabregas
thanks: "Code and data are available at: https://github.com/taliafabs/us-election-analysis.git"
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false
#| eval: true

library(tidyverse)
library(janitor)
library(rstanarm)
library(readr)
library(ggplot2)
library(knitr)
library(arrow)
library(kableExtra)
library(modelsummary)
library(MASS)
library(broom.mixed)
library(gutenbergr)
library(haven)
library(labelled)
library(tidybayes)
library(tidyverse)

## load data
# change file path to the location of cleaned survey and poststrat data on local computer
survey_analysis_data <- arrow::read_parquet("/Users/talia/us-election-analysis/data/analysis_data/survey_analysis_data.parquet")
survey_analysis_subset <- arrow:read_parquet("/Users/talia/us-election-analysis/data/analysis_data/survey_analysis_subset.parquet")

poststrat_analysis_data <- arrow::read_parquet("/Users/talia/us-election-analysis/data/analysis_data/poststrat_analysis_data.parquet")
```


# Introduction

You can and should cross-reference sections and sub-sections. We use @citeR and @rohan.

The 2024 U.S. Presidential election will take place on Tuesday, November 5th. Amidst unprecedented levels of political polarization, American voters are set to see a remat

# Data {#sec-data}

## Survey Data {#sec=survey}
```{r}
#| echo: false
#| warning: false
#| message: false
#| eval: true
#| label: fig-surveyrace
#| fig-cap: Preferred presidential candidates of survey respondents, by gender and race

survey_analysis_subset$vote24 <- ifelse(survey_analysis_subset[,1] == 1, "Joe Biden", "Donald Trump")

survey_analysis_subset |>
  ggplot(aes(x = race, fill = vote24)) +
  stat_count(position = "dodge") +
  facet_wrap(facets = vars(sex)) +
  theme_minimal() +
  labs(
    x = "Race",
    y = "Number of respondents",
    fill = "Preferred Presidential Candidate"
  ) +
  coord_flip() +
  scale_fill_brewer(palette = "Set1") +
  theme(legend.position = "bottom")
```


## Post Stratification Data {#sec-poststrat}



# Model

The goal of our modelling strategy is twofold. Firstly,...

Here we briefly describe the Bayesian analysis model used to investigate... Background details and diagnostics are included in [Appendix -@sec-model-details].

## Model set-up


\begin{align} 
y_i|\mu_i, \sigma &\sim \mbox{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_i + \gamma_i\\
\alpha &\sim \mbox{Normal}(0, 2.5) \\
\beta &\sim \mbox{Normal}(0, 2.5) \\
\gamma &\sim \mbox{Normal}(0, 2.5) \\
\sigma &\sim \mbox{Exponential}(1)
\end{align}

We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use the default priors from `rstanarm`.


### Model justification

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

# use this model to predict the following:
# overall support for biden
# support by state for biden
# electoral college map

# load the model with readRDS
us_election_model <-
  readRDS(file = here::here("models/us_election_model.rds"))
```


# Results {#sec-results}

## Popular Vote Prediction

```{r}
#| echo: false
#| warning: false
#| message: false
#| eval: true
#| include: true
#| label: tbl-popvotepost-popularvote
#| tbl-cap: "2024 U.S. election result estimates for Joe Biden based on post-stratification"
#| tbl-subcap: ["Popular Vote", "Electoral College"]

props <- poststrat_analysis_data %>%
  group_by(state, biden_won, race, hispanic, age_bracket, sex, educ, urban) %>%
  summarise(n = n()) %>%
  ungroup() %>%
  group_by(state) %>%
  mutate(prop = n / sum(n))

num_per_state <- poststrat_analysis_data %>%
  group_by(state) %>%
  summarise(total_respondents = n())
# 
biden_support_by_state <- us_election_model %>%
  add_epred_draws(newdata = props) %>%
  rename(support_biden_predict = .epred) %>%
  mutate(support_biden_predict_prop = support_biden_predict * prop) %>%
  group_by(state, .draw) %>%
  summarise(support_biden_predict = sum(support_biden_predict_prop)) %>%
  group_by(state) %>%
  summarise(
    mean = mean(support_biden_predict),
    lower = quantile(support_biden_predict, 0.025),
    upper = quantile(support_biden_predict, 0.975)
  )
# 
# 
# merged_states <- merge(num_per_state, biden_support_by_state, by="state")
# 
# merged_states$mean_weighted_sum <- merged_states$total_respondents * merged_states$mean
# merged_states$lower_weighted_sum <- merged_states$total_respondents * merged_states$lower
# merged_states$upper_weighted_sum <- merged_states$total_respondents * merged_states$upper
# 
# 
# biden_mean <- sum(merged_states$mean_weighted_sum) / sum(merged_states$total_respondents)
# biden_lower <- sum(merged_states$lower_weighted_sum) / sum(merged_states$total_respondents)
# biden_upper <- sum(merged_states$upper_weighted_sum) / sum(merged_states$total_respondents)
# 
# biden_popvote <- tibble(
#   "Estimate:" = c("Lower Estimate", "Mean Estimate", "Upper Estimate"),
#   "Biden %" = c(round(biden_lower * 100, 2), 
#                 round(biden_mean * 100, 2), 
#                 round(biden_upper * 100, 2)),
#   "Trump %" = c(round((1 - biden_lower) * 100, 2), 
#                 round((1 - biden_mean) * 100, 2), 
#                 round((1 - biden_upper) * 100, 2))
# )
# 
# # Set row names
# rownames(biden_popvote) <- NULL
# 
# # electoral college
# # had chatgpt make me an electoral college csv
# electoral_college <- read_csv("electoral_college_votes.csv", show_col_types = FALSE)
# 
# 
# electoral_college$electoral_votes <- as.numeric(electoral_college$electoral_votes)
# 
# merged_ec <- merge(biden_support_by_state, electoral_college, by = "state")
# 
# biden_states_mean <- merged_ec |>
#   filter(mean >= 0.5)
# 
# trump_states_mean <- merged_ec |>
#   filter(mean < 0.5)
# 
# biden_ec_mean <- sum(biden_states_mean$electoral_votes)
# trump_ec_mean <- sum(trump_states_mean$electoral_votes)
# 
# biden_states_lower <- merged_ec |>
#   filter(lower >= 0.5)
# trump_states_lower <- merged_ec |>
#   filter(lower < 0.5)
# 
# biden_ec_lower <- sum(biden_states_lower$electoral_votes)
# 
# biden_states_upper <- merged_ec |>
#   filter(upper >= 0.5)
# 
# biden_ec_upper <- sum(biden_states_upper$electoral_votes)
# 
# 
# biden_ec_poststrat <- tibble(
#   "Electoral College Estimate:" = c("Lower Estimate", "Mean Estimate", "Upper Estimate"),
#   "Biden" = c(biden_ec_lower, biden_ec_mean, biden_ec_upper),
#   "Trump" = c(538-biden_ec_lower, 538-biden_ec_mean, 538-biden_ec_upper)
# )
# 
# # Set row names
# rownames(biden_ec_poststrat) <- NULL
# 
# # popular vote table
# kable(biden_popvote, align = "c") %>%
#   kable_styling(bootstrap_options = "striped", full_width = F)
# 
# # electoral college table
# kable(biden_ec_poststrat, align = "c") %>%
#   kable_styling(bootstrap_options = "striped", full_width = F)
```

## Electoral College Prediction






# Discussion {#sec-discussion}

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

## Third discussion point

## Weaknesses and Limitations

## Next Steps
Python, more recent data set, softmax regression, gradient descent
Split the survey data into training, validation, and test
Use gradient descent to find the optimal weights to maximize validation accuracy
Apply the model to the post-stratification data
Softmax regression does risk overfitting


\newpage

\appendix

# Appendix {-}


# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check



## Diagnostics


\newpage


# References


